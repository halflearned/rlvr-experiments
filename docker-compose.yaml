# common configurations for both vllm and trainer services
x-common-config: &common-config
  ipc: host
  working_dir: /workspace
  volumes:
    - .:/workspace
  networks:
    - rlvr-net
  deploy:
    resources:
      reservations:
        devices:
          - capabilities: [gpu]

x-common-env: &common-env
  PYTHONPATH: /workspace/src

services:
  vllm:
    <<: *common-config
    image: rlvr-inference:latest
    container_name: inference-server
    entrypoint: []
    command: ["python3", "-u", "entrypoints/inference.py", "configs/inference.toml"]
    environment:
      <<: *common-env
      NVIDIA_VISIBLE_DEVICES: 0
      CUDA_VISIBLE_DEVICES: 0
      VLLM_WORKER_MULTIPROC: 1  #  spawn?
      VLLM_LOGGING_LEVEL: DEBUG
      NCCL_DEBUG: INFO
      NCCL_DEBUG_SUBSYS: INIT,GRAPH,COMM
      NCCL_ASYNC_ERROR_HANDLING: 1
      TORCH_NCCL_BLOCKING_WAIT: 1
      VLLM_USE_V1: 0  # temporary workaround for vLLM v1 issues
    ports:
      - "8000:8000"

  trainer:
    <<: *common-config 
    image: rlvr-training:latest
    container_name: titan-trainer
    command: torchrun --standalone --nnodes=1 --nproc_per_node=4 entrypoints/training.py configs/training.toml
    environment:
      <<: *common-env
      NVIDIA_VISIBLE_DEVICES: 2,3,4,5,6,7
      CUDA_VISIBLE_DEVICES: 2,3,4,5,6,7
      VLLM_BASE_URL: http://vllm:8000/v1

networks:
  rlvr-net:
    driver: bridge