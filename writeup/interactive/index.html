<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RLVR</title>
    <link rel="stylesheet" href="style.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Lora:ital,wght@0,400;0,500;0,600;1,400&family=Source+Code+Pro:wght@400;500&display=swap" rel="stylesheet">
    <!-- D3.js for plots -->
    <script src="https://d3js.org/d3.v7.min.js"></script>
    <!-- Highlight.js for code syntax highlighting -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>
    <!-- KaTeX for math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
        onload="renderMathInElement(document.body, {
            delimiters: [
                {left: '$$', right: '$$', display: true},
                {left: '$', right: '$', display: false}
            ],
            throwOnError: false
        });"></script>
</head>
<body>
    <article>
        <header>
            <h1>RLVR Experiments</h1>
            <p class="subtitle">Subtitle goes here</p>
        </header>

        <section class="intro">
            <p>The first part of this post described our package RLVR Experiments. The second presents a few experiments run with it.</p>
        </section>

        <section id="system-architecture">
            <h3>System overview</h3>
            <p>This report describes the architecture of our GRPO training system—a distributed, asynchronous pipeline for reinforcement learning from verifiable rewards. The system runs generation, verification, and training concurrently, using Ray for orchestration and NCCL for fast weight synchronization. We'll walk through the producer-consumer design, explain the coordination mechanisms, and share what we learned building it.</p>

            <h3>Components</h3>

            <p>In typical usage, the system runs in a producer-consumer pipeline. The producer generates completions and verifies them; the consumer batches them and trains. They run concurrently, communicating through a versioned buffer. This sort of design, decoupling generation from training, has been used in [Kimi 1.5]() and [torchforge](https://pytorch.org/blog/introducing-torchforge/).

            <p>This package provides 5 components:</p>

            <ul>
                <li><strong>Trainer</strong> (TorchTitan): holds the policy model, runs forward/backward, steps the optimizer</li>
                <li><strong>Rollout engine</strong> (vLLM): generates completions from prompts</li>
                <li><strong>Reference model</strong> (vLLM): computes log-probabilities for the KL penalty</li>
                <li><strong>Verifier pool</strong>: checks completions against ground truth, returns binary rewards</li>
                <li><strong>Data iterator</strong>: serves prompts, tracks which are pending/in-flight/done</li>
            </ul>

            <p>Each component is one or more Ray actors. The trainer and vLLM engines can be sharded across GPUs with different parallelism strategies. Weight sync happens periodically over NCCL, transferring updated policy weights from the trainer to the rollout and reference models.</p>
            <h3>Producer loop</h3>
            <p>
                The producer runs dozens of async workers concurrently, all competing for prompts from the data iterator. Each worker independently shepherds one prompt through the full pipeline: generation, verification, reference logprobs, then buffer.
            </p>
            <p>
                The producer has no visibility into the trainer's progress—it just keeps generating until the data is exhausted, pausing only during weight syncs. If a sample doesn't provide enough variation (all-wrong or all-correct) it is <em>filtered out</em> and not attempted again until the next epoch.
            </p>

            <figure>
                <img src="figures/producer.jpg" alt="Producer loop diagram">
            </figure>

            <details class="code-details">
                <summary>Producer code (<code>train_grpo_minimal.py</code>)</summary>
<pre><code class="language-python">async def produce_epoch():
    async def worker():
        while True:
            item = await data_iter.get_next_async()
            if item is None:
                return
            prompt_id = item["problem"]["prompt_id"]
            try:
                # Generate completions from current policy
                response = await rollout.generate_single(item["template"], **sampling_params)
                completions = [out.text for out in response.outputs]
                rollout_sample = RolloutSample.from_vllm(response, pad_token_id)

                # Score with verifier
                rewards = await verify(item["problem"], completions)

                # Skip if all rewards identical (no signal)
                if torch.tensor(rewards).std() &lt; 1e-6:
                    data_iter.mark_done(prompt_id)
                    return

                # Get reference model logprobs (for KL penalty)
                ref_logprobs = await compute_ref_logprobs(rollout_sample)

                # Push to buffer for consumer
                # Tag with trainer_version so consumer can check staleness later
                sample = TrainSample(rollout_sample, rewards, ref_logprobs,
                                     item_id=prompt_id, trainer_version=rollout.trainer_version)
                await buffer.put(sample, rollout.trainer_version, item_id=prompt_id)
            except Exception:
                data_iter.mark_failed(prompt_id)

    async with asyncio.TaskGroup() as tg:
        for _ in range(64):
            tg.create_task(worker())</code></pre>
            </details>

            <h3>Consumer loop</h3>
            <p>
                The consumer is a standard training loop: pull samples, batch them, forward/backward, optimizer step. Only two things are different. First, samples are checked for <em>staleness</em>: if the trainer has moved too far ahead of the weights used for generation, the sample is (lazily) evicted and the prompt is re-queued for generation within this epoch. Note this is a second source of inefficiency. Second, after each optimizer step the trainer version increments, and consumed prompts are marked done so they won't be sampled again this epoch.
            </p>

            <figure>
                <img src="figures/consumer.png" alt="Consumer loop diagram">
            </figure>

            <details class="code-details">
                <summary>Consumer code (<code>train_grpo_minimal.py</code>)</summary>
<pre><code class="language-python">for epoch in range(training.get("num_epochs", 1)):
    data_iter.new_epoch(seed=42 + epoch)
    producer = asyncio.create_task(produce_epoch())

    pending = []
    accum_count = 0

    while True:
        entry = await buffer.pop()
        if entry is None:
            break

        pending.append(entry.item)
        if len(pending) &lt; training["prompts_per_forward_backward"]:
            continue

        # ── Evict stale samples ────────────────────────────────────
        pending = evict_stale(pending)
        if len(pending) &lt; training["prompts_per_forward_backward"]:
            continue  # not enough left after eviction, keep collecting

        # ── Make batch ─────────────────────────────────────────────
        batch, stats = make_batch(pending, pad_token_id)
        group_sizes = [group_size] * len(pending)
        item_ids = [s.item_id for s in pending]
        pending = []

        # ── Compute advantages ────
        advantages = compute_grpo_advantages(batch.rewards, group_sizes=group_sizes)

        # ── Forward + backward (with micro-batching) ───────────────
        loss, _ = await trainer.forward_backward(
            loss_fn,
            batch.input_ids,
            loss_args=(batch.completion_ids, batch.ref_logprobs,
                       batch.logprobs, advantages),
            loss_kwargs={"padding_mask": batch.mask,
                         "prompt_lens": batch.prompt_lens,
                         "temperature": temperature},
            scale_loss=1.0 / accumulation_steps,
            micro_batch_size=get_micro_batch_size(stats.padded_seq_len),
        )

        # Mark items as consumed
        for item_id in item_ids:
            data_iter.mark_done(item_id)

        accum_count += 1
        if accum_count &lt; accumulation_steps:
            continue

        # ── Optimizer step ─────────────────────────────────────────
        grad_norm = await trainer.optim_step()
        accum_count = 0

        # ── Weight sync ──────────────────────────────────────────
        if trainer.version % sync_ref_every == 0:
            await sync_titan_to_vllm(trainer, reference,
                                     trainer_version=trainer.version)
        if trainer.version % sync_model_every == 0:
            await sync_titan_to_vllm(trainer, rollout,
                                     trainer_version=trainer.version)

        if training.get("max_steps") and trainer.version >= training["max_steps"]:
            break

    producer.cancel()
    await asyncio.gather(producer, return_exceptions=True)
    buffer.reset()</code></pre>
            </details>

            <h3>Weight sync</h3>
            <p>
                This is how the trainer's updated weights get to the rollout engine and reference model. The main challenge is copying efficiently when the trainer and rollout models may have weights sharded differently—the trainer might use FSDP-style sharding across 8 GPUs while the rollout uses tensor parallelism across 2. Different packages handle this differently. For example, <a href="#">torchforge</a> uses a fast filesystem, while tlr has a double-buffer scheme...
            </p>
            <p>
                Our strategy is to avoid disk entirely, relying on NCCL communication channels to broadcast weights directly between GPU memory. At initialization time, we create NCCL communicator groups (borrowing vLLM's StatelessProcessGroup class). This allows us to create overlapping "worlds" shared by each trainer-receiver pair.
            </p>
            <ol>
                <li>Pause the rollout engine: block new requests behind an asyncio Event, and either wait for in-flight requests to drain (default) or abort them.</li>
                <li>Prepare the trainer for sync. Each trainer rank builds two things: a parameter map from HuggingFace parameter names to their local DTensor references, and a chunk plan—a list of (parameter name, offset, size) tuples dividing weights into ~100MB pieces. The chunk plan is sent to vLLM workers over Ray so both sides know how to pack and unpack.</li>
                <li>For each chunk: all trainer ranks participate in an all-gather to reconstruct full tensors from their shards (required because DTensor only exposes all-gather, not gather-to-one). Only rank 0 packs the result into a flat buffer and broadcasts over NCCL; vLLM workers receive into their own buffer and unpack into local model parameters, resharding as needed for their own parallelism layout.</li>
                <li>Update the rollout engine's trainer version so newly generated samples are tagged correctly.</li>
                <li>Resume generation: set the Event, blocked workers continue.</li>
            </ol>
            <p>
                With this strategy we complete the entire weight transfer for Qwen3-32B in 3 seconds (compare to torchforge which reportedly takes 52 seconds).
            </p>

            <h3>Visualization</h3>

            <h3>Putting it together</h3>

            <!-- EMBED: pipeline-animation -->
            <details class="visualization-details">
                <summary>Pipeline animation</summary>
                <section class="visualization">
                    <div class="controls">
                        <button id="prev-btn" title="Previous step">&larr;</button>
                        <input type="range" id="time-slider" min="0" max="100" value="0">
                        <button id="next-btn" title="Next step">&rarr;</button>
                        <span id="time-display">0.0s</span>
                        <button id="play-btn" title="Play/Pause">&#9654;</button>
                    </div>

                    <div class="graphs">
                        <div class="graph-container">
                            <h3>Pipeline Timeline</h3>
                            <canvas id="timeline-canvas"></canvas>
                        </div>

                        <div class="graph-container">
                            <h3>Buffer Dynamics</h3>
                            <canvas id="buffer-canvas"></canvas>
                        </div>

                        <div class="graph-container">
                            <h3>Sample Fates</h3>
                            <canvas id="fates-canvas"></canvas>
                        </div>
                    </div>

                    <div class="legend">
                        <div class="legend-item"><span class="color-box" style="background: #3fb950;"></span> Generation</div>
                        <div class="legend-item"><span class="color-box" style="background: #58a6ff;"></span> Reference</div>
                        <div class="legend-item"><span class="color-box" style="background: #a371f7;"></span> Training</div>
                        <div class="legend-item"><span class="color-box" style="background: #f0883e;"></span> Verifier</div>
                        <div class="legend-item"><span class="color-box" style="background: #f85149;"></span> Sync Event</div>
                    </div>
                </section>
            </details>
        </section>

        <section id="experiments">
            <h2>2. Basic experiment setup</h2>
            <p>
                In this section, all experiments use one of two algorithm variants.
            </p>

            <p>For <a href="https://arxiv.org/abs/2503.20783">GRPO</a>, given a prompt $p$, we generate $G$ completions $o_{i}$ from the current model $\pi_{\theta}$, and compute:</p>

            $$
            J_{\text{GRPO}}(g)
            =
            \frac{1}{G} \sum_{i=1}^{G} \sum_{t=1}^{|o_i|}
            \left\{ \min \left[
                \frac{ \pi_{\theta}(o_t | q, o_{\lt t}) }{ \pi_{\theta_{\text{old}}}(o_t | q, o_{\lt t})  } \hat{A}_{i,t}
                ,
                \text{clip}\left(
                    \frac{ \pi_{\theta}(o_t | q, o_{\lt t}) }{ \pi_{\theta_{\text{old}}}(o_t | q, o_{\lt t})  },
                    1 - \varepsilon,
                    1 + \varepsilon
                 \right)
                \hat{A}_{i,t}
             \right] \right\}
            \tag{1}
            $$

            <p>
                where the advantage $\hat{A}_{i} = (r_i - \bar{r}) / \sigma_r$ is the z-scored reward for completion $i$ within its group, $\pi_{\theta_{\text{old}}}$ is the rollout policy used to generate the completions, and the probability ratio is clipped following <a href="https://arxiv.org/pdf/1707.06347">PPO-Clip</a>.
            </p>

            <p>
                Our second algorithm is a variant of <a href="https://arxiv.org/pdf/2503.14476">DAPO</a> (Decoupled Clip and Dynamic Sampling Policy Optimization), which uses the following objective,
            </p>

            $$
            J_{\text{DAPO}}(g)
            =
            \frac{1}{{\color{orange}\sum_{i} |o_i|}} \sum_{i=1}^{G} \sum_{t=1}^{|o_i|}
            \left\{ \min \left[
                \frac{ \pi_{\theta}(o_t | q, o_{\lt t}) }{ \pi_{\theta_{\text{old}}}(o_t | q, o_{\lt t})  } \hat{A}_{i,t}
                ,
                \text{clip}\left(
                    \frac{ \pi_{\theta}(o_t | q, o_{\lt t}) }{ \pi_{\theta_{\text{old}}}(o_t | q, o_{\lt t})  },
                    {\color{teal} 1 - \varepsilon_{\text{low}}},
                    {\color{teal} 1 + \varepsilon_{\text{high}}}
                 \right)
                \hat{A}_{i,t}
             \right] \right\}
            \tag{2}
            $$

            <p>
                the <span style="color: #e8a030;">normalization factor</span> divides by total tokens across the group rather than by $G$, removing a length bias that would otherwise discount longer completions. The <span style="color: teal;">clipping bounds</span> are asymmetric ($\varepsilon_{\text{low}} = 0.2$, $\varepsilon_{\text{high}} = 0.28$), allowing the policy more room to increase probability on rewarded completions than to decrease it on penalized ones.
            </p>

            <p>
                In either implementation, when rewards are constant, we discard the entire prompt. In addition, we ensure that every batch has the same number of prompts per step.
            </p>

            <p>
                We keep a small penalty for divergence with respect to a frozen reference policy $\text{KL}(\pi_\theta \| \pi_{\text{ref}})$. This is implemented using the "<a href="http://joschu.net/blog/kl-approx.html">Schulman</a>" approximation to the forward divergence.
            </p>

            <!-- TODO: EMBED: table with hyperparameters -->

            <section id="staleness">
                <h3>2.1 Staleness</h3>
                <p>
                    If we allow completions generated from earlier model versions to be used, we can reduce...
                </p>
                <p>
                    After <span class="metric" data-run="stale0" data-key="total_steps"></span> steps, the strict on-policy run (<code>max_staleness=0</code>) achieves a final reward of <span class="metric" data-run="stale0" data-key="final_reward"></span>, while allowing one step of staleness (<code>max_staleness=1</code>) reaches <span class="metric" data-run="stale1" data-key="final_reward"></span> over <span class="metric" data-run="stale1" data-key="total_steps"></span> steps.
                </p>



                <!-- EMBED: interactive experiment plots -->
                <div class="experiment-plots">
                    <!-- Preset buttons -->
                    <div id="preset-buttons" class="preset-buttons"></div>

                    <!-- Checkbox legend -->
                    <div id="run-legend" class="run-legend"></div>

                    <h4>Rewards</h4>
                    <div class="plot-row">
                        <div class="plot-container" id="plot-reward"></div>
                        <div class="plot-container" id="plot-allcorr-allwrong"></div>
                        <div class="plot-container" id="plot-completion-len"></div>
                    </div>

                    <h4>Training Dynamics</h4>
                    <div class="plot-row">
                        <div class="plot-container" id="plot-loss-grpo"></div>
                        <div class="plot-container" id="plot-loss-sft"></div>
                        <div class="plot-container" id="plot-kl"></div>
                        <div class="plot-container" id="plot-entropy"></div>
                    </div>

                    <h4>Evaluation</h4>
                    <div class="plot-row">
                        <div class="plot-container" id="plot-eval-gsm8k"></div>
                        <div class="plot-container" id="plot-eval-math"></div>
                    </div>

                    <!-- Dynamic explanation text -->
                    <div id="preset-explanation" class="preset-explanation"></div>
                </div>

                <!-- EMBED: comparison-table (auto-generated) -->
                <div id="staleness-comparison-table" class="results-table-container"></div>


            </section>

            <section id="gsm8k">
                <h3>GSM8K</h3>
            </section>

            <section id="instruction-following">
                <h3>Instruction-following</h3>
            </section>
        </section>

        <section id="appendix" class="appendix">
            <h2>Appendix</h2>

            <section id="datasets">
                <h3>Dataset, verifiers, benchmarks.</h3>
                <p><strong>GSM8K:</strong> The MathVerifier achieves only 8-9% on base model completions compared to lm_eval's 66% strict-match accuracy. This discrepancy is intentional and correct. The base model often continues generating after providing the answer, producing additional unrelated Q&A pairs. MathVerifier extracts the <em>last</em> number in the response, which in these cases comes from the spurious continuation rather than the actual answer. lm_eval's strict-match, by contrast, extracts the <em>first</em> occurrence of "The answer is X." and ignores everything after. While lm_eval's approach is appropriate for evaluation (measuring whether the model <em>can</em> solve the problem), MathVerifier's stricter approach is the right training signal for RL: it rewards completions that both solve the problem correctly <em>and</em> terminate appropriately, rather than giving credit to responses that ramble indefinitely after stating the answer.</p>
                <p><strong>MATH:</strong></p>
            </section>

 
            <section id="passk-rates">
                <h3>Base model pass@k rates</h3>
                <p>
                    We measure prompt difficulty using <strong>pass@k</strong>: the probability of getting at least one
                    correct answer in k samples from the base model. Low pass@k indicates a "hard" prompt (model rarely
                    solves it), while high pass@k indicates an "easy" prompt.
                </p>
                <p>
                    GSM8K is nearly saturated (99.81% solvable with 1024 samples), while IFEval is challenging for
                    base models (only 27% solvable). We generate curriculum orderings by sorting prompts by pass@16
                    in ascending order (hard-to-easy).
                </p>

                <!-- EMBED: passk-table -->
                <div class="results-table-container">
                    <table class="results-table">
                        <thead>
                            <tr>
                                <th>Dataset</th>
                                <th>Prompts</th>
                                <th>pass@1</th>
                                <th>pass@8</th>
                                <th>pass@64</th>
                                <th>pass@256</th>
                                <th>pass@512</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>GSM8K</td>
                                <td>7,473</td>
                                <td>75.0%</td>
                                <td>95.6%</td>
                                <td>99.2%</td>
                                <td>99.7%</td>
                                <td>99.8%</td>
                            </tr>
                            <tr>
                                <td>MATH (L3-5)</td>
                                <td>5,584</td>
                                <td>29.7%</td>
                                <td>57.4%</td>
                                <td>76.5%</td>
                                <td>82.3%</td>
                                <td>84.0%</td>
                            </tr>
                            <tr>
                                <td>MBPP</td>
                                <td>374</td>
                                <td>26.6%</td>
                                <td>54.8%</td>
                                <td>78.6%</td>
                                <td>87.2%</td>
                                <td>89.6%</td>
                            </tr>
                            <tr>
                                <td>IFEval</td>
                                <td>3,200</td>
                                <td>7.6%</td>
                                <td>16.5%</td>
                                <td>23.4%</td>
                                <td>26.0%</td>
                                <td>27.0%</td>
                            </tr>
                        </tbody>
                    </table>
                    <p class="table-caption"><strong>Table 2.</strong> Pass@k rates on training splits. Model: Qwen3-1.7B-Base.</p>
                </div>
            </section>

            <section id="notes">
                <h3>Notes</h3>
                <ol>
                    <li>MFU</li>
                    <li>Kernels: LIGER kernel probably faster than TP=2</li>
                    <li>KL divergence: we use the Schulman "k3" estimator: given $r = \log(\pi_{\text{ref}} / \pi_\theta)$, the quantity $\exp(r) - r - 1$ is an unbiased estimator of $\text{KL}(\pi_\theta \| \pi_{\text{ref}})$, the "forward" KL (policy w.r.t. reference). This penalizes the policy for placing probability mass where the reference does not, which is the standard choice in RLHF/GRPO &mdash; it discourages the policy from straying too far from the reference in a mode-seeking direction.</li>
                    <li>Precision: we use float16 (with dynamic loss scaling) for training rather than bfloat16. On A100 GPUs, we observed that bfloat16 training ran approximately 2x slower for the 1.7B model due to reduced throughput in the GRPO loss computation. One GRPO run (lr=1e-5) was initially launched with bfloat16 and had to be restarted with float16 after observing the slowdown. We did not observe numerical instability from float16 at this model scale.</li>
                </ol>
            </section>
        </section>

        <section id="references">
            <h2>References</h2>
        </section>


                   <section id="staleness-appendix">
                <h3>Staleness conditions</h3>
                <!-- EMBED: staleness-diagrams -->
                <details class="staleness-details">
                    <summary>Staleness diagrams</summary>
                    <div class="staleness-diagrams-combined">
                        <div class="diagrams-stack">
                        <svg viewBox="0 0 380 330" xmlns="http://www.w3.org/2000/svg">
                            <!-- Background -->
                            <rect width="380" height="330" fill="#fafafa"/>

                            <!-- Shared row labels (left side) -->
                            <text x="8" y="52" font-family="Roboto, sans-serif" font-size="9" fill="#666">Trainer</text>
                            <text x="8" y="72" font-family="Roboto, sans-serif" font-size="9" fill="#666">Rollout</text>
                            <text x="8" y="92" font-family="Roboto, sans-serif" font-size="9" fill="#666">Accepts</text>

                            <!-- ===== DIAGRAM 1: Strict on-policy ===== -->
                            <g transform="translate(0, 10)">
                                <!-- Grid lines -->
                                <g stroke="#e0e0e0" stroke-width="0.5">
                                    <line x1="55" y1="30" x2="55" y2="95"/>
                                    <line x1="165" y1="30" x2="165" y2="95"/>
                                    <line x1="275" y1="30" x2="275" y2="95"/>
                                </g>

                                <!-- Trainer row: v0, v1 -->
                                <rect x="55" y="40" width="110" height="16" rx="2" fill="#a371f7"/>
                                <text x="110" y="51" font-family="Roboto, sans-serif" font-size="8" fill="white" text-anchor="middle" font-weight="500">v0</text>
                                <rect x="165" y="40" width="110" height="16" rx="2" fill="#8b5cf6"/>
                                <text x="220" y="51" font-family="Roboto, sans-serif" font-size="8" fill="white" text-anchor="middle" font-weight="500">v1</text>

                                <!-- Rollout row -->
                                <rect x="55" y="58" width="110" height="16" rx="2" fill="#3fb950"/>
                                <text x="110" y="69" font-family="Roboto, sans-serif" font-size="8" fill="white" text-anchor="middle" font-weight="500">v0</text>
                                <rect x="165" y="58" width="110" height="16" rx="2" fill="#22c55e"/>
                                <text x="220" y="69" font-family="Roboto, sans-serif" font-size="8" fill="white" text-anchor="middle" font-weight="500">v1</text>

                                <!-- Accepts row -->
                                <rect x="55" y="76" width="110" height="16" rx="2" fill="#58a6ff"/>
                                <text x="110" y="87" font-family="Roboto, sans-serif" font-size="8" fill="white" text-anchor="middle" font-weight="500">v0</text>
                                <rect x="165" y="76" width="110" height="16" rx="2" fill="#3b82f6"/>
                                <text x="220" y="87" font-family="Roboto, sans-serif" font-size="8" fill="white" text-anchor="middle" font-weight="500">v1</text>

                                <!-- Sync annotation -->
                                <line x1="165" y1="35" x2="165" y2="95" stroke="#22c55e" stroke-width="1.5"/>
                                <text x="165" y="30" font-family="Roboto, sans-serif" font-size="6" fill="#22c55e" text-anchor="middle">sync+optim</text>
                            </g>

                            <!-- ===== DIAGRAM 2: With staleness=1 ===== -->
                            <g transform="translate(0, 115)">
                                <!-- Grid lines -->
                                <g stroke="#e0e0e0" stroke-width="0.5">
                                    <line x1="55" y1="30" x2="55" y2="95"/>
                                    <line x1="110" y1="30" x2="110" y2="95"/>
                                    <line x1="165" y1="30" x2="165" y2="95"/>
                                    <line x1="220" y1="30" x2="220" y2="95"/>
                                    <line x1="275" y1="30" x2="275" y2="95"/>
                                </g>

                                <!-- Trainer row: v0, v1, v2, v3 -->
                                <rect x="55" y="40" width="55" height="16" rx="2" fill="#a371f7"/>
                                <text x="82" y="51" font-family="Roboto, sans-serif" font-size="8" fill="white" text-anchor="middle" font-weight="500">v0</text>
                                <rect x="110" y="40" width="55" height="16" rx="2" fill="#8b5cf6"/>
                                <text x="137" y="51" font-family="Roboto, sans-serif" font-size="8" fill="white" text-anchor="middle" font-weight="500">v1</text>
                                <rect x="165" y="40" width="55" height="16" rx="2" fill="#7c3aed"/>
                                <text x="192" y="51" font-family="Roboto, sans-serif" font-size="8" fill="white" text-anchor="middle" font-weight="500">v2</text>
                                <rect x="220" y="40" width="55" height="16" rx="2" fill="#6d28d9"/>
                                <text x="247" y="51" font-family="Roboto, sans-serif" font-size="8" fill="white" text-anchor="middle" font-weight="500">v3</text>

                                <!-- Rollout row: v0, v2 -->
                                <rect x="55" y="58" width="110" height="16" rx="2" fill="#3fb950"/>
                                <text x="110" y="69" font-family="Roboto, sans-serif" font-size="8" fill="white" text-anchor="middle" font-weight="500">v0</text>
                                <rect x="165" y="58" width="110" height="16" rx="2" fill="#22c55e"/>
                                <text x="220" y="69" font-family="Roboto, sans-serif" font-size="8" fill="white" text-anchor="middle" font-weight="500">v2</text>

                                <!-- Accepts row -->
                                <rect x="55" y="76" width="55" height="16" rx="2" fill="#58a6ff"/>
                                <text x="82" y="87" font-family="Roboto, sans-serif" font-size="8" fill="white" text-anchor="middle" font-weight="500">v0</text>
                                <rect x="110" y="76" width="55" height="16" rx="2" fill="#3b82f6"/>
                                <text x="137" y="87" font-family="Roboto, sans-serif" font-size="7" fill="white" text-anchor="middle" font-weight="500">v0,v1</text>
                                <rect x="165" y="76" width="55" height="16" rx="2" fill="#2563eb"/>
                                <text x="192" y="87" font-family="Roboto, sans-serif" font-size="8" fill="white" text-anchor="middle" font-weight="500">v2</text>
                                <rect x="220" y="76" width="55" height="16" rx="2" fill="#1d4ed8"/>
                                <text x="247" y="87" font-family="Roboto, sans-serif" font-size="7" fill="white" text-anchor="middle" font-weight="500">v2,v3</text>

                                <!-- Annotations -->
                                <line x1="110" y1="35" x2="110" y2="95" stroke="#a371f7" stroke-width="1.5"/>
                                <text x="110" y="30" font-family="Roboto, sans-serif" font-size="6" fill="#a371f7" text-anchor="middle">optim</text>
                                <line x1="165" y1="35" x2="165" y2="95" stroke="#22c55e" stroke-width="1.5"/>
                                <text x="165" y="30" font-family="Roboto, sans-serif" font-size="6" fill="#22c55e" text-anchor="middle">sync+optim</text>
                                <line x1="220" y1="35" x2="220" y2="95" stroke="#a371f7" stroke-width="1.5"/>
                                <text x="220" y="30" font-family="Roboto, sans-serif" font-size="6" fill="#a371f7" text-anchor="middle">optim</text>
                                <line x1="275" y1="35" x2="275" y2="95" stroke="#22c55e" stroke-width="1.5"/>
                                <text x="275" y="30" font-family="Roboto, sans-serif" font-size="6" fill="#22c55e" text-anchor="middle">sync+optim</text>
                            </g>

                            <!-- ===== DIAGRAM 3: Starvation ===== -->
                            <g transform="translate(0, 220)">
                                <!-- Grid lines -->
                                <g stroke="#e0e0e0" stroke-width="0.5">
                                    <line x1="55" y1="30" x2="55" y2="95"/>
                                    <line x1="110" y1="30" x2="110" y2="95"/>
                                    <line x1="165" y1="30" x2="165" y2="95"/>
                                    <line x1="220" y1="30" x2="220" y2="95"/>
                                    <line x1="275" y1="30" x2="275" y2="95"/>
                                </g>

                                <!-- Trainer row: v0, v1 then nothing -->
                                <rect x="55" y="40" width="55" height="16" rx="2" fill="#a371f7"/>
                                <text x="82" y="51" font-family="Roboto, sans-serif" font-size="8" fill="white" text-anchor="middle" font-weight="500">v0</text>
                                <rect x="110" y="40" width="55" height="16" rx="2" fill="#8b5cf6"/>
                                <text x="137" y="51" font-family="Roboto, sans-serif" font-size="8" fill="white" text-anchor="middle" font-weight="500">v1</text>

                                <!-- Rollout row: v0 then nothing -->
                                <rect x="55" y="58" width="110" height="16" rx="2" fill="#3fb950"/>
                                <text x="110" y="69" font-family="Roboto, sans-serif" font-size="8" fill="white" text-anchor="middle" font-weight="500">v0</text>

                                <!-- Accepts row: v0, then DEADLOCK -->
                                <rect x="55" y="76" width="55" height="16" rx="2" fill="#58a6ff"/>
                                <text x="82" y="87" font-family="Roboto, sans-serif" font-size="8" fill="white" text-anchor="middle" font-weight="500">v0</text>
                                <rect x="110" y="76" width="55" height="16" rx="2" fill="#f85149" fill-opacity="0.2" stroke="#f85149" stroke-width="1.5" stroke-dasharray="3,2"/>
                                <text x="137" y="87" font-family="Roboto, sans-serif" font-size="7" fill="#f85149" text-anchor="middle" font-weight="500">DEAD</text>

                                <!-- Annotation -->
                                <line x1="110" y1="35" x2="110" y2="95" stroke="#f85149" stroke-width="1.5"/>
                                <text x="110" y="30" font-family="Roboto, sans-serif" font-size="6" fill="#f85149" text-anchor="middle">optim&rarr;deadlock</text>

                                <!-- Time axis (only on bottom diagram) -->
                                <line x1="40" y1="100" x2="285" y2="100" stroke="#999" stroke-width="0.5"/>
                                <text x="55" y="108" font-family="Roboto, sans-serif" font-size="7" fill="#999" text-anchor="middle">0</text>
                                <text x="110" y="108" font-family="Roboto, sans-serif" font-size="7" fill="#999" text-anchor="middle">8</text>
                                <text x="165" y="108" font-family="Roboto, sans-serif" font-size="7" fill="#999" text-anchor="middle">16</text>
                                <text x="220" y="108" font-family="Roboto, sans-serif" font-size="7" fill="#999" text-anchor="middle">24</text>
                                <text x="275" y="108" font-family="Roboto, sans-serif" font-size="7" fill="#999" text-anchor="middle">32</text>
                            </g>
                        </svg>
                    </div>
                    <div class="diagrams-captions">
                        <div class="diagram-caption-item">
                            <strong>Strict on-policy</strong><br>
                            <code>staleness=0, optim=16, sync=16</code><br>
                            All advance together. No starvation, but no parallelism.
                        </div>
                        <div class="diagram-caption-item">
                            <strong>With staleness</strong><br>
                            <code>staleness=1, optim=8, sync=16</code><br>
                            Trainer advances every 8. Rollout syncs to v2 at t=16. No v1 data, but no starvation.
                        </div>
                        <div class="diagram-caption-item">
                            <strong>Starvation</strong><br>
                            <code>staleness=0, optim=8, sync=16</code><br>
                            At t=8, trainer needs v1 but rollout is at v0 &rarr; deadlock.
                        </div>
                    </div>
                    </div>
                </details>
            </section>

    </article>

    <script src="viewer.js"></script>
    <script src="staleness_plots.js?v=10"></script>
    <script>hljs.highlightAll();</script>
</body>
</html>
